{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HTAod7UkqrD1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import TfidfTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgw0HTFdoeQf",
        "outputId": "b861518b-61e9-4b25-87b7-37a659646c62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the Data in DataFrames \n",
        "lockdown=pd.read_csv(\"/content/drive/MyDrive/ProjectPhase2/nyt_topic/nyt_topic_lockdown.csv\")\n",
        "masking=pd.read_csv(\"/content/drive/MyDrive/ProjectPhase2/nyt_topic/nyt_topic_masking.csv\")\n",
        "vaccination=pd.read_csv(\"/content/drive/MyDrive/ProjectPhase2/nyt_topic/nyt_topic_vaccination.csv\")\n",
        "secondary_vaccination=pd.read_csv(\"/content/drive/MyDrive/ProjectPhase2/changeorg_topic/changeorg_topic_vaccination.csv\")"
      ],
      "metadata": {
        "id": "nkjhxLd6rjHy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lockdownTF=lockdown['lockdown'].tolist()\n",
        "counterT=0\n",
        "counterF=0\n",
        "for i in lockdownTF:\n",
        "  if i == True:\n",
        "    counterT+=1\n",
        "  else:\n",
        "    counterF+=1\n",
        "\n",
        "print(counterT)\n",
        "print(counterF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0RI85XJr-k_",
        "outputId": "9d3172ce-23f4-4b1d-ed2f-a841250fe58f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "81\n",
            "732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskingTF=masking['masking'].tolist()\n",
        "counterT=0\n",
        "counterF=0\n",
        "for i in maskingTF:\n",
        "  if i == True:\n",
        "    counterT+=1\n",
        "  else:\n",
        "    counterF+=1\n",
        "\n",
        "print(counterT)\n",
        "print(counterF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlijN2G5s3IA",
        "outputId": "65dfdab3-ea56-42eb-d605-ae3283416b54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "218\n",
            "595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vaccinationTF=vaccination['vaccination'].tolist()\n",
        "counterT=0\n",
        "counterF=0\n",
        "for i in vaccinationTF:\n",
        "  if i == True:\n",
        "    counterT+=1\n",
        "  else:\n",
        "    counterF+=1\n",
        "\n",
        "print(counterT)\n",
        "print(counterF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ-ptF56tKUX",
        "outputId": "06a13bd8-d8a2-497c-c2ee-9685f0bfdd96"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "477\n",
            "336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vaccination"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2EmSdJ5N2lNk",
        "outputId": "d8e5b34c-fd18-41af-9ef3-6d6930e182fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  vaccination\n",
              "0                     This was predicted in the Spring        False\n",
              "1    Insist on vaccinations or make them stay home....         True\n",
              "2    If employers can make a drug test mandatory as...         True\n",
              "3    Dozens to hundreds of people crowding together...        False\n",
              "4    If people were bleeding out their eyes and ear...         True\n",
              "..                                                 ...          ...\n",
              "808  I went out for lunch yesterday with a friend. ...        False\n",
              "809  Even a year and a half later, I don't understa...         True\n",
              "810  Let me get this straight. Vaccinated people ar...         True\n",
              "811  I have not suffered from a cold or the flu for...        False\n",
              "812  I cannot understand why people are still stand...        False\n",
              "\n",
              "[813 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f741e587-73e4-4f4f-81df-a28cb6a6c7c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>vaccination</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This was predicted in the Spring</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Insist on vaccinations or make them stay home....</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If employers can make a drug test mandatory as...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dozens to hundreds of people crowding together...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If people were bleeding out their eyes and ear...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>I went out for lunch yesterday with a friend. ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>Even a year and a half later, I don't understa...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>Let me get this straight. Vaccinated people ar...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>811</th>\n",
              "      <td>I have not suffered from a cold or the flu for...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812</th>\n",
              "      <td>I cannot understand why people are still stand...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>813 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f741e587-73e4-4f4f-81df-a28cb6a6c7c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f741e587-73e4-4f4f-81df-a28cb6a6c7c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f741e587-73e4-4f4f-81df-a28cb6a6c7c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) DATA PARTITIONING\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "z_gggbkFYDhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Partitioning the Primary Data into Train (70%) and Test (30%)\n",
        "statement_train,statement_test,label_train,label_test=train_test_split(vaccination.text,vaccination.vaccination,train_size=0.7,random_state=50)"
      ],
      "metadata": {
        "id": "S0IM9-N2tnCQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Considering whole Secondary Data as Test Data\n",
        "secondary_statement_test,secondary_label_test=secondary_vaccination.text,secondary_vaccination.vaccination"
      ],
      "metadata": {
        "id": "rmSBze_JCX2L"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dlaK301_Ce5V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type(statement_test)\n",
        "# type(secondary_label_test)\n",
        "# label_test\n",
        "# label_train"
      ],
      "metadata": {
        "id": "GT8WRf2l3Ggk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iRiOkviLTXU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) BASELINE MODEL TRAINING\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_J6XaTgtYKIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Model Training with BOW\n",
        "count_vect = CountVectorizer()\n",
        "statement_train_final=count_vect.fit_transform(statement_train)\n",
        "#print(len(count_vect.vocabulary_))\n",
        "statement_test_final=count_vect.transform(statement_test)\n",
        "#print(len(count_vect.vocabulary_))\n",
        "secondary_statement_test_final=count_vect.transform(secondary_statement_test)"
      ],
      "metadata": {
        "id": "_Bj-yQjBq5QN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#statement_train_final.shape\n",
        "#statement_test_final\n",
        "#len(count_vect.get_feature_names())\n",
        "#type(statement_train_final)"
      ],
      "metadata": {
        "id": "U_XOdGRP1-E6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Model Evaluation 1\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "DWw6QF23EaFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "statement_train_final_array=statement_train_final.toarray()\n",
        "label_train_final_array=label_train\n"
      ],
      "metadata": {
        "id": "BnTiIJbjWO94"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression().fit(statement_train_final_array,label_train_final_array)\n",
        "predicted_primary = lr_model.predict(statement_test_final.toarray())\n",
        "# type(statement_train_final_array)"
      ],
      "metadata": {
        "id": "XVfYi72VEY6x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(statement_test)\n",
        "#predicted_primary"
      ],
      "metadata": {
        "id": "7Sje_V0pvRtB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(predicted_primary==label_test)"
      ],
      "metadata": {
        "id": "NMCbQaoBwJuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d346a8-b5da-4cd9-a4b9-2fea3f7b2cb2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9139344262295082"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "secondary_statement_test_final_array=secondary_statement_test_final.toarray()\n",
        "predicted_secondary=lr_model.predict(secondary_statement_test_final_array)"
      ],
      "metadata": {
        "id": "ILklq9GQBE0C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(predicted_secondary==secondary_label_test)"
      ],
      "metadata": {
        "id": "GDpfjmPHEIm-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f541d-0df3-4e72-8131-ef29470a709a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9866666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of Primary Dataset : 91.39344262295082 %                       \n",
        "\n",
        "\n",
        "Accuracy of Secondary Dataset : 98.66666666666667 %\n"
      ],
      "metadata": {
        "id": "VPsQWAUoEgYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#statement_train"
      ],
      "metadata": {
        "id": "D0Xxudy1doad"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Feature Engineering                                                \n",
        "\n",
        "---\n",
        "\n",
        "i) Data Cleaning + lemmatization ii)TF-IDF iii) regular Expression ( Specific Word / Word Sequence"
      ],
      "metadata": {
        "id": "xPAEj5AlE6R0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature 1 - Data cleaning and Lemmatization\n",
        "def cleaning(text):\n",
        "\n",
        "  stemm = PorterStemmer()\n",
        "  lemm = WordNetLemmatizer()\n",
        "  text_lower = text.lower()\n",
        "  #print(type(document))\n",
        "  word_token = word_tokenize(text_lower)\n",
        "  #print(words)\n",
        "  word_length = [word for word in word_token if len(word) > 1]\n",
        "  word_alphabet = [word for word in word_length if word.isalpha()]\n",
        "  words_without_stopword = [word for word in word_alphabet if word not in stopwords.words(\"english\")]\n",
        "  #Stemming degrades the accuracy \n",
        "  #words = [stemm.stem(word) for word in tokens]\n",
        "  lemmatized_words = [lemm.lemmatize(word, pos='v') for word in words_without_stopword]\n",
        "  # join words to make sentence\n",
        "  final_word = \" \".join(lemmatized_words)\n",
        "  \n",
        "  return final_word"
      ],
      "metadata": {
        "id": "yaS1zevFZWmI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaning primary train data\n",
        "statement_train_clean=statement_train.apply(cleaning)\n",
        "statement_train_clean.shape\n",
        "print(type(statement_train))\n",
        "#cleaning primary test data\n",
        "statement_test_clean=statement_test.apply(cleaning)\n",
        "#cleaning secondary test data\n",
        "statement_test_clean_secondary=secondary_statement_test.apply(cleaning)"
      ],
      "metadata": {
        "id": "t_3o_Zm3EipG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3687a655-6eee-45f0-cc8a-146dbd16aa21"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the word with most occurances for feature 3\n",
        "from collections import Counter\n",
        "def count(text):\n",
        "  text1=text.lower()\n",
        "  text2=word_tokenize(text1)\n",
        "  #text3=Counter(text2)\n",
        "  return text2\n",
        "nb=[]\n",
        "varr=statement_train_clean.apply(count)\n",
        "for i in varr:\n",
        "  for j in i:\n",
        "    nb.append(j)\n",
        "    \n",
        "nb1=Counter(nb)\n",
        "#newvar=statement_train.str.split()\n",
        "#varr=Counter(newvar)\n",
        "#varr\n",
        "#var2=Counter(varr)\n",
        "#var2\n",
        "nb1.most_common(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anOzBxXCUgGU",
        "outputId": "d96a5c30-187e-4381-cc2d-15f108c6c7dc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('vaccinate', 349),\n",
              " ('get', 321),\n",
              " ('people', 306),\n",
              " ('mask', 240),\n",
              " ('vaccine', 234)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#statement_train_clean\n",
        "#statement_test_clean\n",
        "#statement_test_clean_secondary"
      ],
      "metadata": {
        "id": "y97D8_b7XpAI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fit Bag of Words Model\n",
        "count_vect = CountVectorizer()\n",
        "#primary train \n",
        "statement_train_final_clean=count_vect.fit_transform(statement_train_clean)\n",
        "#primary test\n",
        "statement_test_final_clean=count_vect.transform(statement_test_clean)\n",
        "#secondary test\n",
        "statement_test_final_clean_secondary=count_vect.transform(statement_test_clean_secondary)"
      ],
      "metadata": {
        "id": "N_fYm6b1qZQb"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature 2 - Tf-Idf \n",
        "  \n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "#primary train\n",
        "tf_transformer = tfidf_transformer.fit_transform(statement_train_final_clean)\n",
        "#primary test\n",
        "tf_transformer_test = tfidf_transformer.transform(statement_test_final_clean)\n",
        "#secondary test\n",
        "tf_transformer_test_secondary = tfidf_transformer.transform(statement_test_final_clean_secondary)\n",
        "tf_transformer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvog-6oEMlr_",
        "outputId": "363d2cca-bb49-4dcc-cfa4-a9c461d89a78"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 3435)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#statement_test_final.shape\n",
        "#type(tf_transformer)"
      ],
      "metadata": {
        "id": "M24Y8QeXXgBb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking the model accuracy after 2 features\n",
        "#lr_model11 = LogisticRegression().fit(tf_transformer.toarray(),label_train)\n",
        "#predicted_primary1 = lr_model11.predict(tf_transformer_test.toarray())\n",
        "#np.mean(predicted_primary1==label_test)\n",
        "#predicted_primary11=lr_model11.predict(tf_transformer_test_secondary.toarray())\n",
        "#np.mean(predicted_primary11==secondary_label_test)\\\n",
        "#statement_train"
      ],
      "metadata": {
        "id": "d0Rvat1tMl2n"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature 3 - Regular Expression \n",
        "import re\n",
        "from textblob import TextBlob\n",
        "def regex(text):\n",
        "  #unique words\n",
        "  #return len(set(text.split()))\n",
        "  #Statement Sentiment\n",
        "  #return TextBlob(text).sentiment.polarity\n",
        "  return int(bool(re.search(r\"vaccin\\w+\",text)))"
      ],
      "metadata": {
        "id": "3Lhri2e1CSE-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying the Regular Expresssion and Adding the feature to the model using np.insert\n",
        "\n",
        "#for primary train\n",
        "sentiment_statement_train=statement_train.apply(regex)\n",
        "#sentiment_statement_train_final=[np.round(x) for x in sentiment_statement_train]\n",
        "#print(sentiment_statement_train)\n",
        "\n",
        "final_statement_train_primary = np.insert(tf_transformer.todense(),tf_transformer.shape[1],sentiment_statement_train,axis=1)\n",
        "#final_statement.shape\n",
        "\n",
        "#for primary test\n",
        "sentiment_statement_test=statement_test.apply(regex)\n",
        "#sentiment_statement_test_final=[np.round(x) for x in sentiment_statement_test]\n",
        "#print(sentiment_statement_test)\n",
        "\n",
        "final_statement_test_primary = np.insert(tf_transformer_test.todense(),tf_transformer_test.shape[1],sentiment_statement_test,axis=1)\n",
        "\n",
        "#for secondary test\n",
        "sentiment_statement_test_secondary=secondary_statement_test.apply(regex)\n",
        "#sentiment_statement_test_final_secondary=[np.round(x) for x in sentiment_statement_test_secondary]\n",
        "#print(sentiment_statement_test_final_secondary)\n",
        "\n",
        "final_statement_test_secondary = np.insert(tf_transformer_test_secondary.todense(),tf_transformer_test_secondary.shape[1],sentiment_statement_test_secondary,axis=1)"
      ],
      "metadata": {
        "id": "2tvS3aV5HaHg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracies after feature engineering\n",
        "#74.59\n",
        "#87.29\n",
        "#88.11\n",
        "#88\n",
        "#88.52\n",
        "#np.asarray(final_statement).shape\n",
        "#statement_test_final_clean.shapet\n",
        "#type(final_statement_train_primary)"
      ],
      "metadata": {
        "id": "p5rqLwT7hHo9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Model Evalutation 2\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "A0QhFQS9IKFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "final_Accuracy=LogisticRegression().fit(final_statement_train_primary,label_train)\n",
        "#Accuracy of the Primary Data set after Feature Engineering\n",
        "prediction=final_Accuracy.predict(final_statement_test_primary)\n",
        "np.mean(prediction==label_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EUL2loNLbaF",
        "outputId": "d7f89b2e-6069-45df-afb6-fdc58788fb9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.930327868852459"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuract if the Secondary Dataset after Feature Engineering\n",
        "predicted_secondary2 = final_Accuracy.predict(final_statement_test_secondary)\n",
        "np.mean(predicted_secondary2==secondary_label_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNZUyzJjbyTn",
        "outputId": "a300ee73-3a6a-47fb-8727-243a74cde9e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9873333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of Primary Dataset : 93.0327868852459 %\n",
        "\n",
        "Accuracy of Secondary Dataset : 98.73333333333333 %"
      ],
      "metadata": {
        "id": "ZAfBEEWUIraV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Gaussian_model2 = GaussianNB().fit(final_statement_train_primary,label_train)\n",
        "#predicted_primary2 = Gaussian_model2.predict(final_statement_test_primary)\n",
        "#np.mean(predicted_primary2==label_test)\n",
        "#Gaussian_model3 = GaussianNB().fit(np.asarray(final_statement_train_primary),label_train_final_array)"
      ],
      "metadata": {
        "id": "QYe7OPNaGoKu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking\n",
        "\n",
        "\n",
        "text1=pd.Series(\"I already got the second dose of my pfizer vaccine and I do not have any side effects\")\n",
        "#text2=pd.Series(\"Lockdown is must\")\n",
        "#text3=pd.Series(\"Everyone needs to wear mask and maintain 5 feet distance \")\n",
        "\n",
        "test_cleaning=text1.apply(cleaning)\n",
        "test_next=count_vect.transform(test_cleaning)\n",
        "test_next2 = tfidf_transformer.transform(test_next)\n",
        "test_next3=text1.apply(regex)\n",
        "test_final_1 = np.insert(test_next2.todense(),test_next2.shape[1],test_next3,axis=1)\n",
        "test_predict=final_Accuracy.predict(test_final_1)\n",
        "test_predict"
      ],
      "metadata": {
        "id": "eBKc9TF7EjX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39893514-7a31-4b6b-b16a-48ed370ea30f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:593: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "# 1)https://developers.google.com/edu/python/regular-expressions#:~:text=%5Cw%20%2D%2D%20(lowercase%20w),between%20word%20and%20non%2Dword\n",
        "# 2)https://python.plainenglish.io/understand-regular-expression-in-python-3189979a749\n",
        "# 3)https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
        "# 4)https://gist.github.com/DerrickHiggins/20c77745b080e3d493231424d7da9a2f"
      ],
      "metadata": {
        "id": "X9fFqboYYdp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RfJslQkZItSa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}